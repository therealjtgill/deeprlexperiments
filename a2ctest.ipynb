{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function get_variable in module tensorflow.python.ops.variable_scope:\n",
      "\n",
      "get_variable(name, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, collections=None, caching_device=None, partitioner=None, validate_shape=True, use_resource=None, custom_getter=None, constraint=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>)\n",
      "    Gets an existing variable with these parameters or create a new one.\n",
      "    \n",
      "    This function prefixes the name with the current variable scope\n",
      "    and performs reuse checks. See the\n",
      "    [Variable Scope How To](https://tensorflow.org/guide/variables)\n",
      "    for an extensive description of how reusing works. Here is a basic example:\n",
      "    \n",
      "    ```python\n",
      "    def foo():\n",
      "      with tf.variable_scope(\"foo\", reuse=tf.AUTO_REUSE):\n",
      "        v = tf.get_variable(\"v\", [1])\n",
      "      return v\n",
      "    \n",
      "    v1 = foo()  # Creates v.\n",
      "    v2 = foo()  # Gets the same, existing v.\n",
      "    assert v1 == v2\n",
      "    ```\n",
      "    \n",
      "    If initializer is `None` (the default), the default initializer passed in\n",
      "    the variable scope will be used. If that one is `None` too, a\n",
      "    `glorot_uniform_initializer` will be used. The initializer can also be\n",
      "    a Tensor, in which case the variable is initialized to this value and shape.\n",
      "    \n",
      "    Similarly, if the regularizer is `None` (the default), the default regularizer\n",
      "    passed in the variable scope will be used (if that is `None` too,\n",
      "    then by default no regularization is performed).\n",
      "    \n",
      "    If a partitioner is provided, a `PartitionedVariable` is returned.\n",
      "    Accessing this object as a `Tensor` returns the shards concatenated along\n",
      "    the partition axis.\n",
      "    \n",
      "    Some useful partitioners are available.  See, e.g.,\n",
      "    `variable_axis_size_partitioner` and `min_max_variable_partitioner`.\n",
      "    \n",
      "    Args:\n",
      "      name: The name of the new or existing variable.\n",
      "      shape: Shape of the new or existing variable.\n",
      "      dtype: Type of the new or existing variable (defaults to `DT_FLOAT`).\n",
      "      initializer: Initializer for the variable if one is created. Can either be\n",
      "        an initializer object or a Tensor. If it's a Tensor, its shape must be known\n",
      "        unless validate_shape is False.\n",
      "      regularizer: A (Tensor -> Tensor or None) function; the result of\n",
      "        applying it on a newly created variable will be added to the collection\n",
      "        `tf.GraphKeys.REGULARIZATION_LOSSES` and can be used for regularization.\n",
      "      trainable: If `True` also add the variable to the graph collection\n",
      "        `GraphKeys.TRAINABLE_VARIABLES` (see `tf.Variable`).\n",
      "      collections: List of graph collections keys to add the Variable to.\n",
      "        Defaults to `[GraphKeys.GLOBAL_VARIABLES]` (see `tf.Variable`).\n",
      "      caching_device: Optional device string or function describing where the\n",
      "        Variable should be cached for reading.  Defaults to the Variable's\n",
      "        device.  If not `None`, caches on another device.  Typical use is to\n",
      "        cache on the device where the Ops using the Variable reside, to\n",
      "        deduplicate copying through `Switch` and other conditional statements.\n",
      "      partitioner: Optional callable that accepts a fully defined `TensorShape`\n",
      "        and `dtype` of the Variable to be created, and returns a list of\n",
      "        partitions for each axis (currently only one axis can be partitioned).\n",
      "      validate_shape: If False, allows the variable to be initialized with a\n",
      "          value of unknown shape. If True, the default, the shape of initial_value\n",
      "          must be known. For this to be used the initializer must be a Tensor and\n",
      "          not an initializer object.\n",
      "      use_resource: If False, creates a regular Variable. If true, creates an\n",
      "        experimental ResourceVariable instead with well-defined semantics.\n",
      "        Defaults to False (will later change to True). When eager execution is\n",
      "        enabled this argument is always forced to be True.\n",
      "      custom_getter: Callable that takes as a first argument the true getter, and\n",
      "        allows overwriting the internal get_variable method.\n",
      "        The signature of `custom_getter` should match that of this method,\n",
      "        but the most future-proof version will allow for changes:\n",
      "        `def custom_getter(getter, *args, **kwargs)`.  Direct access to\n",
      "        all `get_variable` parameters is also allowed:\n",
      "        `def custom_getter(getter, name, *args, **kwargs)`.  A simple identity\n",
      "        custom getter that simply creates variables with modified names is:\n",
      "        ```python\n",
      "        def custom_getter(getter, name, *args, **kwargs):\n",
      "          return getter(name + '_suffix', *args, **kwargs)\n",
      "        ```\n",
      "      constraint: An optional projection function to be applied to the variable\n",
      "        after being updated by an `Optimizer` (e.g. used to implement norm\n",
      "        constraints or value constraints for layer weights). The function must\n",
      "        take as input the unprojected Tensor representing the value of the\n",
      "        variable and return the Tensor for the projected value\n",
      "        (which must have the same shape). Constraints are not safe to\n",
      "        use when doing asynchronous distributed training.\n",
      "      synchronization: Indicates when a distributed a variable will be\n",
      "        aggregated. Accepted values are constants defined in the class\n",
      "        `tf.VariableSynchronization`. By default the synchronization is set to\n",
      "        `AUTO` and the current `DistributionStrategy` chooses\n",
      "        when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      "        `trainable` must not be set to `True`.\n",
      "      aggregation: Indicates how a distributed variable will be aggregated.\n",
      "        Accepted values are constants defined in the class\n",
      "        `tf.VariableAggregation`.\n",
      "    \n",
      "    Returns:\n",
      "      The created or existing `Variable` (or `PartitionedVariable`, if a\n",
      "      partitioner was used).\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: when creating a new variable and shape is not declared,\n",
      "        when violating reuse during variable creation, or when `initializer` dtype\n",
      "        and `dtype` don't match. Reuse is set inside `variable_scope`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.get_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function placeholder in module tensorflow.python.ops.array_ops:\n",
      "\n",
      "placeholder(dtype, shape=None, name=None)\n",
      "    Inserts a placeholder for a tensor that will be always fed.\n",
      "    \n",
      "    **Important**: This tensor will produce an error if evaluated. Its value must\n",
      "    be fed using the `feed_dict` optional argument to `Session.run()`,\n",
      "    `Tensor.eval()`, or `Operation.run()`.\n",
      "    \n",
      "    For example:\n",
      "    \n",
      "    ```python\n",
      "    x = tf.compat.v1.placeholder(tf.float32, shape=(1024, 1024))\n",
      "    y = tf.matmul(x, x)\n",
      "    \n",
      "    with tf.compat.v1.Session() as sess:\n",
      "      print(sess.run(y))  # ERROR: will fail because x was not fed.\n",
      "    \n",
      "      rand_array = np.random.rand(1024, 1024)\n",
      "      print(sess.run(y, feed_dict={x: rand_array}))  # Will succeed.\n",
      "    ```\n",
      "    \n",
      "    @compatibility(eager)\n",
      "    Placeholders are not compatible with eager execution.\n",
      "    @end_compatibility\n",
      "    \n",
      "    Args:\n",
      "      dtype: The type of elements in the tensor to be fed.\n",
      "      shape: The shape of the tensor to be fed (optional). If the shape is not\n",
      "        specified, you can feed a tensor of any shape.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor` that may be used as a handle for feeding a value, but not\n",
      "      evaluated directly.\n",
      "    \n",
      "    Raises:\n",
      "      RuntimeError: if eager execution is enabled\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function square in module tensorflow.python.ops.gen_math_ops:\n",
      "\n",
      "square(x, name=None)\n",
      "    Computes square of x element-wise.\n",
      "    \n",
      "    I.e., \\\\(y = x * x = x^2\\\\).\n",
      "    \n",
      "    Args:\n",
      "      x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor`. Has the same type as `x`.\n",
      "    \n",
      "      If `x` is a `SparseTensor`, returns\n",
      "      `SparseTensor(x.indices, tf.math.square(x.values, ...), x.dense_shape)`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FfAgent(object):\n",
    "    def __init__(self, session, input_size, output_size):\n",
    "        self.session = session\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.observations_ph = tf.placeholder(dtype=tf.float32, shape=[None, self.input_size])\n",
    "        # expected sum of discounted rewards\n",
    "        self.esdr_ph = tf.placeholder(dtype=tf.float32, shape=[None, self.output_size])\n",
    "        #self.reward_ph = tf.placeholder(dtype=tf.float32, shape=[None, 1])\n",
    "        \n",
    "        # Shared-parameter policy and value network\n",
    "        W1 = tf.get_variable(\"w1\", [self.input_size, 5])\n",
    "        b1 = tf.get_variable(\"b1\", [5])\n",
    "        W2p = tf.get_variable(\"w2p\", [5, self.output_size]) # policy\n",
    "        b2p = tf.get_variable(\"b2p\", [self.output_size])\n",
    "        W2v = tf.get_variable(\"w2v\", [5, 1]) # value\n",
    "        b2v = tf.get_variable(\"b2v\", [1])\n",
    "        \n",
    "        l1 = tf.nn.relu(tf.matmul(self.observations_ph, W1) + b1)\n",
    "        # this will need to be changed to accommodate the range and character of action values\n",
    "        l2p = tf.nn.relu(tf.matmul(l1, W2p) + b2p)\n",
    "        l2v = tf.nn.relu(tf.matmul(l1, W2v) + b2v)\n",
    "        \n",
    "        self.loss = -1.*tf.reduce_sum(self.esdr_ph*tf.log(lwp)) + tf.reduce_sum(tf.square(l2v - self.esdr_ph))\n",
    "        \n",
    "        self.action_predictions = l2p\n",
    "        self.esdr_predictions = l2v\n",
    "        \n",
    "    def trainSarBatches(self, sars):\n",
    "        '''\n",
    "        Expects sars to be a numpy array of shape [batch_size, 3]\n",
    "        sars = [[state_t, action_t, reward_t+1], ...]\n",
    "        '''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
